#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸš€ ç¬¬ä¸€ä¸ªå¤§æ¨¡å‹åº”ç”¨ - æŒç»­äº¤äº’ç‰ˆæœ¬
====================================

è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„å¤§æ¨¡å‹åº”ç”¨ç¤ºä¾‹ï¼Œå±•ç¤ºå¦‚ä½•ï¼š
1. ä»ç¯å¢ƒå˜é‡è¯»å–APIé…ç½®
2. è°ƒç”¨OpenAIå…¼å®¹çš„å¤§æ¨¡å‹API
3. å¤„ç†åŸºç¡€å¯¹è¯å’Œè§’è‰²æ‰®æ¼”
4. å®ç°é”™è¯¯å¤„ç†æœºåˆ¶
5. æ”¯æŒæŒç»­äº¤äº’å’Œå¤šè½®å¯¹è¯
"""

import os
import sys
from pathlib import Path
from dotenv import load_dotenv
from openai import OpenAI

def init_environment():
    """åˆå§‹åŒ–ç¯å¢ƒé…ç½®"""
    # è·å–é¡¹ç›®æ ¹ç›®å½•è·¯å¾„ï¼ˆå½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•çš„ä¸Šçº§ç›®å½•ï¼‰
    project_root = Path(__file__).parent.parent
    env_file = project_root / ".env"
    
    # åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶
    load_dotenv(dotenv_path=env_file)
    
    # æ˜¾ç¤ºç¯å¢ƒæ–‡ä»¶è·¯å¾„ä¿¡æ¯
    print(f"ğŸ“ é¡¹ç›®æ ¹ç›®å½•: {project_root}")
    print(f"ğŸ“„ ç¯å¢ƒæ–‡ä»¶è·¯å¾„: {env_file}")
    print(f"ğŸ“‹ ç¯å¢ƒæ–‡ä»¶å­˜åœ¨: {'âœ… æ˜¯' if env_file.exists() else 'âŒ å¦'}")
    
    return env_file

def check_api_config():
    """æ£€æŸ¥APIé…ç½®"""
    api_key = os.getenv('OPENAI_API_KEY')
    base_url = os.getenv('OPENAI_BASE_URL')
    model = os.getenv('DEFAULT_MODEL')
    
    if not api_key:
        print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°APIå¯†é’¥ï¼")
        print("è¯·ç¡®ä¿ï¼š")
        print("1. å·²åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º.envæ–‡ä»¶ï¼ˆå¯ä»env.templateå¤åˆ¶ï¼‰")
        print("2. åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®äº†OPENAI_API_KEY")
        return None, None, None
    
    return api_key, base_url, model

def create_client(api_key, base_url):
    """åˆ›å»ºOpenAIå®¢æˆ·ç«¯"""
    client = OpenAI(
        api_key=api_key,
        base_url=base_url
    )
    return client

def print_welcome():
    """æ‰“å°æ¬¢è¿ä¿¡æ¯"""
    print("\n" + "="*60)
    print("ğŸ¤– æ¬¢è¿ä½¿ç”¨AIåŠ©æ‰‹ï¼")
    print("="*60)
    print("ğŸ’¡ ä½¿ç”¨è¯´æ˜ï¼š")
    print("   â€¢ ç›´æ¥è¾“å…¥æ‚¨çš„é—®é¢˜æˆ–æƒ³æ³•")
    print("   â€¢ è¾“å…¥ 'quit'ã€'exit' æˆ– 'q' é€€å‡ºç¨‹åº")
    print("   â€¢ è¾“å…¥ 'clear' æ¸…ç©ºå¯¹è¯å†å²")
    print("   â€¢ è¾“å…¥ 'help' æŸ¥çœ‹å¸®åŠ©ä¿¡æ¯")
    print("="*60)

def print_help():
    """æ‰“å°å¸®åŠ©ä¿¡æ¯"""
    print("\nğŸ“š å¸®åŠ©ä¿¡æ¯ï¼š")
    print("="*40)
    print("ğŸ”¤ åŸºæœ¬å‘½ä»¤ï¼š")
    print("   quit/exit/q  - é€€å‡ºç¨‹åº")
    print("   clear        - æ¸…ç©ºå¯¹è¯å†å²")
    print("   help         - æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯")
    print("   stats        - æ˜¾ç¤ºä¼šè¯ç»Ÿè®¡")
    print("\nğŸ’¬ å¯¹è¯æŠ€å·§ï¼š")
    print("   â€¢ å¯ä»¥è¿›è¡Œå¤šè½®å¯¹è¯ï¼ŒAIä¼šè®°ä½ä¸Šä¸‹æ–‡")
    print("   â€¢ å°è¯•ä¸åŒç±»å‹çš„é—®é¢˜ï¼šç¿»è¯‘ã€ç¼–ç¨‹ã€åˆ›æ„ç­‰")
    print("   â€¢ å¦‚æœå›ç­”ä¸æ»¡æ„ï¼Œå¯ä»¥è¦æ±‚æ›´è¯¦ç»†çš„è§£é‡Š")
    print("="*40)

def print_stats(total_messages, total_tokens):
    """æ‰“å°ä¼šè¯ç»Ÿè®¡ä¿¡æ¯"""
    print(f"\nğŸ“Š ä¼šè¯ç»Ÿè®¡ï¼š")
    print(f"   ğŸ’¬ æ€»å¯¹è¯è½®æ•°: {total_messages}")
    print(f"   ğŸ”¤ æ€»æ¶ˆè€—tokens: {total_tokens}")

def get_user_input():
    """è·å–ç”¨æˆ·è¾“å…¥"""
    try:
        user_input = input("\nğŸ‘¤ æ‚¨: ").strip()
        return user_input
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ æ£€æµ‹åˆ°Ctrl+Cï¼Œæ­£åœ¨é€€å‡º...")
        return "quit"
    except EOFError:
        print("\n\nğŸ‘‹ æ£€æµ‹åˆ°EOFï¼Œæ­£åœ¨é€€å‡º...")
        return "quit"

def chat_with_ai(client, model, messages, max_tokens, temperature):
    """ä¸AIè¿›è¡Œå¯¹è¯"""
    try:
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            max_tokens=max_tokens,
            temperature=temperature
        )
        
        reply = response.choices[0].message.content
        usage = response.usage
        
        return reply, usage
    except Exception as e:
        print(f"âŒ APIè°ƒç”¨å¤±è´¥: {str(e)}")
        print("\nğŸ”§ æ•…éšœæ’é™¤å»ºè®®ï¼š")
        print("1. æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®")
        print("2. ç¡®è®¤ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
        print("3. æ£€æŸ¥APIæœåŠ¡æ˜¯å¦å¯ç”¨")
        print("4. ç¡®è®¤è´¦æˆ·ä½™é¢æ˜¯å¦å……è¶³")
        return None, None

def main():
    """ä¸»ç¨‹åºå…¥å£"""
    print("ğŸš€ LLM-101: å¤§æ¨¡å‹æŒç»­äº¤äº’åº”ç”¨")
    print("=" * 50)
    
    # 1. åˆå§‹åŒ–ç¯å¢ƒ
    env_file = init_environment()
    
    # 2. æ£€æŸ¥APIé…ç½®
    api_key, base_url, model = check_api_config()
    if not api_key:
        return
    
    # 3. åˆ›å»ºå®¢æˆ·ç«¯
    client = create_client(api_key, base_url)
    
    print(f"âœ… å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
    print(f"ğŸ“¡ APIåœ°å€: {base_url}")
    print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model}")
    
    # 4. è·å–é…ç½®å‚æ•°
    max_tokens = int(os.getenv('MAX_TOKENS', '1000'))
    temperature = float(os.getenv('TEMPERATURE', '0.7'))
    
    # 5. åˆå§‹åŒ–å¯¹è¯å†å²
    messages = [
        {
            "role": "system", 
            "content": "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹ï¼Œç”¨ä¸­æ–‡å›ç­”é—®é¢˜ã€‚è¯·ç®€æ´æ˜äº†åœ°å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œä¿æŒå¯¹è¯çš„è¿è´¯æ€§ã€‚"
        }
    ]
    
    # 6. ä¼šè¯ç»Ÿè®¡
    total_messages = 0
    total_tokens = 0
    
    # 7. æ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯
    print_welcome()
    
    # 8. ä¸»å¯¹è¯å¾ªç¯
    while True:
        # è·å–ç”¨æˆ·è¾“å…¥
        user_input = get_user_input()
        
        # å¤„ç†ç‰¹æ®Šå‘½ä»¤
        if user_input.lower() in ['quit', 'exit', 'q']:
            print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨AIåŠ©æ‰‹ï¼Œå†è§ï¼")
            print_stats(total_messages, total_tokens)
            break
        elif user_input.lower() == 'clear':
            # æ¸…ç©ºå¯¹è¯å†å²ï¼Œä¿ç•™ç³»ç»Ÿæç¤º
            messages = [messages[0]]  # åªä¿ç•™ç³»ç»Ÿæ¶ˆæ¯
            total_messages = 0
            total_tokens = 0
            print("ğŸ§¹ å¯¹è¯å†å²å·²æ¸…ç©ºï¼")
            continue
        elif user_input.lower() == 'help':
            print_help()
            continue
        elif user_input.lower() == 'stats':
            print_stats(total_messages, total_tokens)
            continue
        elif not user_input:
            print("âš ï¸  è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼Œæˆ–è¾“å…¥ 'help' æŸ¥çœ‹å¸®åŠ©")
            continue
        
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å¯¹è¯å†å²
        messages.append({
            "role": "user",
            "content": user_input
        })
        
        # è°ƒç”¨AIè¿›è¡Œå¯¹è¯
        print("ğŸ¤– AIåŠ©æ‰‹æ­£åœ¨æ€è€ƒ...")
        reply, usage = chat_with_ai(client, model, messages, max_tokens, temperature)
        
        if reply is None:
            # å¦‚æœAPIè°ƒç”¨å¤±è´¥ï¼Œç§»é™¤åˆšæ·»åŠ çš„ç”¨æˆ·æ¶ˆæ¯
            messages.pop()
            continue
        
        # æ·»åŠ AIå›å¤åˆ°å¯¹è¯å†å²
        messages.append({
            "role": "assistant",
            "content": reply
        })
        
        # æ˜¾ç¤ºAIå›å¤
        print(f"\nğŸ¤– AIåŠ©æ‰‹: {reply}")
        
        # æ˜¾ç¤ºæœ¬è½®ç»Ÿè®¡
        print(f"\nğŸ“Š æœ¬è½®ç»Ÿè®¡: è¾“å…¥{usage.prompt_tokens} + è¾“å‡º{usage.completion_tokens} = æ€»è®¡{usage.total_tokens} tokens")
        
        # æ›´æ–°æ€»ç»Ÿè®¡
        total_messages += 1
        total_tokens += usage.total_tokens
        
        # æ§åˆ¶å¯¹è¯å†å²é•¿åº¦ï¼ˆå¯é€‰ï¼‰
        # å¦‚æœå¯¹è¯å†å²å¤ªé•¿ï¼Œå¯ä»¥ä¿ç•™æœ€è¿‘çš„å‡ è½®å¯¹è¯
        if len(messages) > 21:  # ç³»ç»Ÿæ¶ˆæ¯ + 10è½®å¯¹è¯ï¼ˆæ¯è½®2æ¡æ¶ˆæ¯ï¼‰
            # ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯å’Œæœ€è¿‘çš„10è½®å¯¹è¯
            messages = [messages[0]] + messages[-20:]
            print("ğŸ’¡ å¯¹è¯å†å²å·²è‡ªåŠ¨ç²¾ç®€ï¼Œä¿ç•™æœ€è¿‘10è½®å¯¹è¯")

if __name__ == "__main__":
    main() 
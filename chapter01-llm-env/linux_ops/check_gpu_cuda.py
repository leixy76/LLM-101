#!/usr/bin/env python3
"""
LLM-101 GPU å’Œ CUDA ç¯å¢ƒæ£€æŸ¥è„šæœ¬
ç”¨äºéªŒè¯ NVIDIA GPU é©±åŠ¨å’Œ CUDA æ˜¯å¦æ­£ç¡®å®‰è£…
"""

import os
import sys
import subprocess
import platform

def print_header(title):
    """æ‰“å°æ ‡é¢˜"""
    print(f"\n{'='*60}")
    print(f"ğŸ” {title}")
    print(f"{'='*60}")

def run_command(cmd, description=""):
    """è¿è¡Œå‘½ä»¤å¹¶è¿”å›ç»“æœ"""
    try:
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
        return result.returncode == 0, result.stdout, result.stderr
    except Exception as e:
        return False, "", str(e)

def check_system_info():
    """æ£€æŸ¥ç³»ç»Ÿä¿¡æ¯"""
    print_header("ç³»ç»Ÿä¿¡æ¯")
    print(f"æ“ä½œç³»ç»Ÿ: {platform.system()} {platform.release()}")
    print(f"æ¶æ„: {platform.machine()}")
    print(f"Pythonç‰ˆæœ¬: {sys.version}")
    
    # æ£€æŸ¥Ubuntuç‰ˆæœ¬
    if platform.system() == "Linux":
        success, output, _ = run_command("lsb_release -a")
        if success:
            print(f"Linuxå‘è¡Œç‰ˆä¿¡æ¯:")
            print(output)

def check_nvidia_gpu():
    """æ£€æŸ¥NVIDIA GPUç¡¬ä»¶"""
    print_header("NVIDIA GPU ç¡¬ä»¶æ£€æŸ¥")
    
    # æ£€æŸ¥PCIè®¾å¤‡
    success, output, _ = run_command("lspci | grep -i nvidia")
    if success and output.strip():
        print("âœ… æ£€æµ‹åˆ°NVIDIA GPUç¡¬ä»¶:")
        print(output)
        return True
    else:
        print("âŒ æœªæ£€æµ‹åˆ°NVIDIA GPUç¡¬ä»¶")
        return False

def check_nvidia_driver():
    """æ£€æŸ¥NVIDIAé©±åŠ¨"""
    print_header("NVIDIA é©±åŠ¨æ£€æŸ¥")
    
    success, output, _ = run_command("nvidia-smi")
    if success:
        print("âœ… NVIDIAé©±åŠ¨å·²å®‰è£…å¹¶æ­£å¸¸å·¥ä½œ:")
        print(output)
        return True
    else:
        print("âŒ NVIDIAé©±åŠ¨æœªå®‰è£…æˆ–æ— æ³•æ­£å¸¸å·¥ä½œ")
        print("è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…é©±åŠ¨:")
        print("sudo apt install -y ubuntu-drivers-common")
        print("sudo ubuntu-drivers autoinstall")
        print("sudo reboot")
        return False

def check_cuda():
    """æ£€æŸ¥CUDA"""
    print_header("CUDA æ£€æŸ¥")
    
    # æ£€æŸ¥nvccå‘½ä»¤
    success, output, _ = run_command("nvcc --version")
    if success:
        print("âœ… CUDAå·²å®‰è£…:")
        print(output)
        cuda_installed = True
    else:
        print("âŒ CUDAæœªå®‰è£…æˆ–nvccå‘½ä»¤ä¸å¯ç”¨")
        cuda_installed = False
    
    # æ£€æŸ¥CUDAè·¯å¾„
    cuda_paths = [
        "/usr/local/cuda",
        "/usr/local/cuda-12.1",
        "/usr/local/cuda-11.8"
    ]
    
    print("\nğŸ“ CUDAå®‰è£…è·¯å¾„æ£€æŸ¥:")
    for path in cuda_paths:
        if os.path.exists(path):
            print(f"âœ… å‘ç°CUDAè·¯å¾„: {path}")
        else:
            print(f"âŒ æœªæ‰¾åˆ°CUDAè·¯å¾„: {path}")
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    print("\nğŸ”§ ç¯å¢ƒå˜é‡æ£€æŸ¥:")
    cuda_home = os.environ.get('CUDA_HOME')
    cuda_path = os.environ.get('PATH', '')
    cuda_lib = os.environ.get('LD_LIBRARY_PATH', '')
    
    print(f"CUDA_HOME: {cuda_home if cuda_home else 'æœªè®¾ç½®'}")
    print(f"PATHåŒ…å«CUDA: {'âœ…' if 'cuda' in cuda_path.lower() else 'âŒ'}")
    print(f"LD_LIBRARY_PATHåŒ…å«CUDA: {'âœ…' if 'cuda' in cuda_lib.lower() else 'âŒ'}")
    
    return cuda_installed

def check_python_gpu_libraries():
    """æ£€æŸ¥Python GPUåº“"""
    print_header("Python GPU åº“æ£€æŸ¥")
    
    libraries = [
        ("torch", "PyTorch"),
        ("tensorflow", "TensorFlow"),
        ("cupy", "CuPy"),
        ("numba", "Numba")
    ]
    
    for lib_name, display_name in libraries:
        try:
            __import__(lib_name)
            print(f"âœ… {display_name} å·²å®‰è£…")
            
            # ç‰¹åˆ«æ£€æŸ¥PyTorchçš„CUDAæ”¯æŒ
            if lib_name == "torch":
                import torch
                print(f"   PyTorchç‰ˆæœ¬: {torch.__version__}")
                print(f"   CUDAå¯ç”¨: {'âœ…' if torch.cuda.is_available() else 'âŒ'}")
                if torch.cuda.is_available():
                    print(f"   CUDAç‰ˆæœ¬: {torch.version.cuda}")
                    print(f"   GPUæ•°é‡: {torch.cuda.device_count()}")
                    for i in range(torch.cuda.device_count()):
                        print(f"   GPU {i}: {torch.cuda.get_device_name(i)}")
                        
        except ImportError:
            print(f"âŒ {display_name} æœªå®‰è£…")

def check_conda_environment():
    """æ£€æŸ¥Condaç¯å¢ƒ"""
    print_header("Conda ç¯å¢ƒæ£€æŸ¥")
    
    # æ£€æŸ¥condaå‘½ä»¤
    success, output, _ = run_command("conda --version")
    if success:
        print(f"âœ… Condaå·²å®‰è£…: {output.strip()}")
    else:
        print("âŒ Condaæœªå®‰è£…")
        return False
    
    # æ£€æŸ¥å½“å‰ç¯å¢ƒ
    current_env = os.environ.get('CONDA_DEFAULT_ENV', 'base')
    print(f"å½“å‰ç¯å¢ƒ: {current_env}")
    
    # åˆ—å‡ºæ‰€æœ‰ç¯å¢ƒ
    success, output, _ = run_command("conda env list")
    if success:
        print("å¯ç”¨ç¯å¢ƒ:")
        print(output)
    
    return True

def provide_recommendations():
    """æä¾›å»ºè®®"""
    print_header("ç¯å¢ƒé…ç½®å»ºè®®")
    
    print("ğŸ“‹ å®Œæ•´çš„ç¯å¢ƒé…ç½®æ­¥éª¤:")
    print("1. æ£€æŸ¥GPUç¡¬ä»¶: lspci | grep -i nvidia")
    print("2. å®‰è£…NVIDIAé©±åŠ¨: sudo ubuntu-drivers autoinstall")
    print("3. é‡å¯ç³»ç»Ÿ: sudo reboot")
    print("4. å®‰è£…CUDA 12.1:")
    print("   wget https://developer.download.nvidia.com/compute/cuda/12.1.0/local_installers/cuda_12.1.0_530.30.02_linux.run")
    print("   sudo sh cuda_12.1.0_530.30.02_linux.run --silent --toolkit --toolkitpath=/usr/local/cuda-12.1 --no-opengl-libs --override")
    print("5. è®¾ç½®ç¯å¢ƒå˜é‡:")
    print("   echo 'export PATH=\"/usr/local/cuda-12.1/bin:$PATH\"' >> ~/.bashrc")
    print("   echo 'export LD_LIBRARY_PATH=\"/usr/local/cuda-12.1/lib64:$LD_LIBRARY_PATH\"' >> ~/.bashrc")
    print("   source ~/.bashrc")
    print("6. åˆ›å»ºCondaç¯å¢ƒ: conda create -n llm101 python=3.10.18")
    print("7. æ¿€æ´»ç¯å¢ƒ: conda activate llm101")
    print("8. å®‰è£…PyTorch: pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121")
    
    print("\nğŸ”§ è‡ªåŠ¨åŒ–è„šæœ¬:")
    print("è¿è¡Œé¡¹ç›®æä¾›çš„è‡ªåŠ¨åŒ–è„šæœ¬: ./chapter01-llm-env/setup_llm101_dev.sh")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ LLM-101 GPU å’Œ CUDA ç¯å¢ƒæ£€æŸ¥")
    print("=" * 60)
    
    # ç³»ç»Ÿä¿¡æ¯
    check_system_info()
    
    # GPUç¡¬ä»¶æ£€æŸ¥
    gpu_hardware = check_nvidia_gpu()
    
    # é©±åŠ¨æ£€æŸ¥
    driver_ok = check_nvidia_driver() if gpu_hardware else False
    
    # CUDAæ£€æŸ¥
    cuda_ok = check_cuda()
    
    # Pythonåº“æ£€æŸ¥
    check_python_gpu_libraries()
    
    # Condaç¯å¢ƒæ£€æŸ¥
    conda_ok = check_conda_environment()
    
    # æ€»ç»“
    print_header("ç¯å¢ƒæ£€æŸ¥æ€»ç»“")
    print(f"GPUç¡¬ä»¶: {'âœ…' if gpu_hardware else 'âŒ'}")
    print(f"NVIDIAé©±åŠ¨: {'âœ…' if driver_ok else 'âŒ'}")
    print(f"CUDA: {'âœ…' if cuda_ok else 'âŒ'}")
    print(f"Conda: {'âœ…' if conda_ok else 'âŒ'}")
    
    if not (gpu_hardware and driver_ok and cuda_ok):
        provide_recommendations()
    else:
        print("\nğŸ‰ æ­å–œï¼æ‚¨çš„GPUå’ŒCUDAç¯å¢ƒé…ç½®æ­£ç¡®ï¼")
        print("å¯ä»¥å¼€å§‹ä½¿ç”¨LLM-101è¿›è¡Œå¤§æ¨¡å‹å¼€å‘äº†ï¼")

if __name__ == "__main__":
    main() 
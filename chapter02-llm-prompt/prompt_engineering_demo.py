#!/usr/bin/env python3
"""
ğŸ¯ LLM-101 æç¤ºè¯å·¥ç¨‹ç¤ºä¾‹
å±•ç¤ºä¸åŒçš„æç¤ºè¯æŠ€å·§ï¼šé›¶æ ·æœ¬ã€å°‘æ ·æœ¬ã€æ€ç»´é“¾ã€è‡ªæˆ‘åæ€ç­‰
"""

import os
import json
from typing import List, Dict, Any
from dotenv import load_dotenv
from openai import OpenAI

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

class PromptEngineeringDemo:
    """æç¤ºè¯å·¥ç¨‹æ¼”ç¤ºç±»"""
    
    def __init__(self):
        self.client = self.setup_client()
        self.model = "gpt-3.5-turbo"
    
    def setup_client(self):
        """è®¾ç½®APIå®¢æˆ·ç«¯"""
        if os.getenv("OPENAI_API_KEY"):
            return OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        elif os.getenv("DEEPSEEK_API_KEY"):
            return OpenAI(
                api_key=os.getenv("DEEPSEEK_API_KEY"),
                base_url="https://api.deepseek.com"
            )
        else:
            raise ValueError("è¯·è®¾ç½®OPENAI_API_KEYæˆ–DEEPSEEK_API_KEYç¯å¢ƒå˜é‡")
    
    def call_llm(self, messages: List[Dict[str, str]], temperature: float = 0.7) -> str:
        """è°ƒç”¨å¤§æ¨¡å‹"""
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=temperature,
                max_tokens=1000
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"âŒ è°ƒç”¨å¤±è´¥: {str(e)}"
    
    def zero_shot_example(self, text: str) -> str:
        """é›¶æ ·æœ¬å­¦ä¹ ç¤ºä¾‹"""
        prompt = f"è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬çš„æƒ…æ„Ÿå€¾å‘ï¼ˆç§¯æã€æ¶ˆæã€ä¸­æ€§ï¼‰ï¼š\n\n{text}"
        
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æƒ…æ„Ÿåˆ†æåŠ©æ‰‹ã€‚"},
            {"role": "user", "content": prompt}
        ]
        
        return self.call_llm(messages)
    
    def few_shot_example(self, text: str) -> str:
        """å°‘æ ·æœ¬å­¦ä¹ ç¤ºä¾‹"""
        prompt = f"""è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬çš„æƒ…æ„Ÿå€¾å‘ã€‚

                    ç¤ºä¾‹ï¼š
                    æ–‡æœ¬ï¼šä»Šå¤©å¤©æ°”çœŸå¥½ï¼Œå¿ƒæƒ…å¾ˆæ„‰å¿«ï¼
                    æƒ…æ„Ÿï¼šç§¯æ

                    æ–‡æœ¬ï¼šè¿™éƒ¨ç”µå½±å¤ªæ— èŠäº†ï¼Œæµªè´¹æ—¶é—´ã€‚
                    æƒ…æ„Ÿï¼šæ¶ˆæ

                    æ–‡æœ¬ï¼šä»Šå¤©æ˜¯å‘¨ä¸€ï¼Œå¼€å§‹æ–°çš„ä¸€å‘¨ã€‚
                    æƒ…æ„Ÿï¼šä¸­æ€§

                    ç°åœ¨è¯·åˆ†æï¼š
                    æ–‡æœ¬ï¼š{text}
                    æƒ…æ„Ÿï¼š"""
        
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æƒ…æ„Ÿåˆ†æåŠ©æ‰‹ã€‚"},
            {"role": "user", "content": prompt}
        ]
        
        return self.call_llm(messages)
    
    def chain_of_thought_example(self, text: str) -> str:
        """æ€ç»´é“¾(CoT)ç¤ºä¾‹"""
        prompt = f"""è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬çš„æƒ…æ„Ÿå€¾å‘ã€‚è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤è¿›è¡Œåˆ†æï¼š

                        1. é¦–å…ˆï¼Œè¯†åˆ«æ–‡æœ¬ä¸­çš„å…³é”®è¯å’ŒçŸ­è¯­
                        2. ç„¶åï¼Œåˆ†æè¿™äº›è¯è¯­çš„æƒ…æ„Ÿè‰²å½©
                        3. æ¥ç€ï¼Œè€ƒè™‘æ•´ä½“è¯­å¢ƒå’Œè¯­è°ƒ
                        4. æœ€åï¼Œç»¼åˆåˆ¤æ–­æƒ…æ„Ÿå€¾å‘ï¼ˆç§¯æã€æ¶ˆæã€ä¸­æ€§ï¼‰

                        æ–‡æœ¬ï¼š{text}

                        è¯·é€æ­¥åˆ†æï¼š"""
        
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æƒ…æ„Ÿåˆ†æåŠ©æ‰‹ï¼Œå–„äºé€æ­¥åˆ†æé—®é¢˜ã€‚"},
            {"role": "user", "content": prompt}
        ]
        
        return self.call_llm(messages, temperature=0.3)
    
    def self_reflection_example(self, text: str) -> str:
        """è‡ªæˆ‘åæ€ç¤ºä¾‹"""
        print("ğŸ”„ è‡ªæˆ‘åæ€è¿‡ç¨‹å±•ç¤ºï¼š")
        print("=" * 50)
        
        # ç¬¬ä¸€æ­¥ï¼šåˆå§‹åˆ†æ
        print("ğŸ“‹ ç¬¬ä¸€æ­¥ï¼šåˆå§‹åˆ†æ")
        print("-" * 30)
        initial_prompt = f"è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬çš„æƒ…æ„Ÿå€¾å‘ï¼š\n\n{text}"
        
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æƒ…æ„Ÿåˆ†æåŠ©æ‰‹ã€‚"},
            {"role": "user", "content": initial_prompt}
        ]
        
        initial_response = self.call_llm(messages)
        print(f"åˆå§‹åˆ†æç»“æœï¼š\n{initial_response}")
        print("-" * 30)
        
        # ç¬¬äºŒæ­¥ï¼šè‡ªæˆ‘åæ€å’Œæ”¹è¿›
        print("\nğŸ¤” ç¬¬äºŒæ­¥ï¼šè‡ªæˆ‘åæ€å’Œæ”¹è¿›")
        print("-" * 30)
        reflection_prompt = f"""ä½ åˆšæ‰çš„åˆ†æç»“æœæ˜¯ï¼š
                            {initial_response}

                            ç°åœ¨è¯·é‡æ–°å®¡è§†è¿™ä¸ªåˆ†æï¼š
                            1. è¿™ä¸ªåˆ†ææ˜¯å¦å‡†ç¡®ï¼Ÿ
                            2. æœ‰æ²¡æœ‰é—æ¼çš„é‡è¦ä¿¡æ¯ï¼Ÿ
                            3. æ˜¯å¦éœ€è¦è°ƒæ•´ç»“è®ºï¼Ÿ

                            è¯·ç»™å‡ºä½ çš„æœ€ç»ˆåˆ†æç»“æœã€‚

                            åŸæ–‡æœ¬ï¼š{text}"""
        
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå–„äºè‡ªæˆ‘åæ€å’Œæ”¹è¿›çš„æƒ…æ„Ÿåˆ†æåŠ©æ‰‹ã€‚"},
            {"role": "user", "content": reflection_prompt}
        ]
        
        final_response = self.call_llm(messages, temperature=0.3)
        print(f"åæ€æ”¹è¿›ç»“æœï¼š\n{final_response}")
        print("-" * 30)
        
        # å¯¹æ¯”æ€»ç»“
        print("\nğŸ“Š å¯¹æ¯”æ€»ç»“ï¼š")
        print("ğŸ”¹ åˆå§‹åˆ†æï¼šæ›´ç›´æ¥ï¼ŒåŸºäºç¬¬ä¸€å°è±¡")
        print("ğŸ”¹ åæ€æ”¹è¿›ï¼šæ›´æ·±å…¥ï¼Œè€ƒè™‘å¤šä¸ªè§’åº¦ï¼Œç»“è®ºæ›´å¯é ")
        print("=" * 50)
        
        return final_response
    
    def role_playing_example(self, product_description: str) -> str:
        """è§’è‰²æ‰®æ¼”ç¤ºä¾‹"""
        prompt = f"""ä½ ç°åœ¨æ˜¯ä¸€ä½èµ„æ·±çš„ç”µå•†æ–‡æ¡ˆä¸“å®¶ï¼Œæ‹¥æœ‰10å¹´çš„è¥é”€ç»éªŒã€‚ä½ çš„ä»»åŠ¡æ˜¯ä¸ºä»¥ä¸‹äº§å“å†™ä¸€æ®µå¸å¼•äººçš„è¥é”€æ–‡æ¡ˆã€‚

                    è¦æ±‚ï¼š
                    - çªå‡ºäº§å“çš„æ ¸å¿ƒå–ç‚¹
                    - ä½¿ç”¨æƒ…æ„ŸåŒ–çš„è¯­è¨€
                    - åŒ…å«è¡ŒåŠ¨å·å¬
                    - æ–‡æ¡ˆé•¿åº¦æ§åˆ¶åœ¨100å­—ä»¥å†…

                    äº§å“æè¿°ï¼š{product_description}

                    è¯·å†™å‡ºè¥é”€æ–‡æ¡ˆï¼š"""
        
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„ç”µå•†æ–‡æ¡ˆä¸“å®¶ï¼Œæ“…é•¿åˆ›ä½œæœ‰è¯´æœåŠ›çš„è¥é”€æ–‡æ¡ˆã€‚"},
            {"role": "user", "content": prompt}
        ]
        
        return self.call_llm(messages)
    
    def structured_output_example(self, text: str) -> str:
        """ç»“æ„åŒ–è¾“å‡ºç¤ºä¾‹"""
        prompt = f"""è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬å¹¶ä»¥JSONæ ¼å¼è¿”å›ç»“æœï¼š

                        æ–‡æœ¬ï¼š{text}

                        è¯·è¿”å›ä»¥ä¸‹æ ¼å¼çš„JSONï¼š
                        {{
                            "sentiment": "ç§¯æ/æ¶ˆæ/ä¸­æ€§",
                            "confidence": 0.0-1.0,
                            "keywords": ["å…³é”®è¯1", "å…³é”®è¯2", "å…³é”®è¯3"],
                            "summary": "ç®€çŸ­æ€»ç»“",
                            "reasoning": "åˆ†æç†ç”±"
                        }}

                        è¯·ç¡®ä¿è¿”å›çš„æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ã€‚"""
        
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æƒ…æ„Ÿåˆ†æåŠ©æ‰‹ï¼Œæ€»æ˜¯è¿”å›ç»“æ„åŒ–çš„JSONç»“æœã€‚"},
            {"role": "user", "content": prompt}
        ]
        
        return self.call_llm(messages, temperature=0.3)
    
    def run_comparison(self, text: str):
        """è¿è¡Œæ‰€æœ‰ç¤ºä¾‹å¹¶æ¯”è¾ƒç»“æœ"""
        print("ğŸ¯ æç¤ºè¯å·¥ç¨‹æŠ€å·§å¯¹æ¯”åˆ†æ")
        print("=" * 60)
        print(f"ğŸ“ åˆ†ææ–‡æœ¬: {text}")
        print("=" * 60)
        
        techniques = [
            ("é›¶æ ·æœ¬å­¦ä¹ ", self.zero_shot_example),
            ("å°‘æ ·æœ¬å­¦ä¹ ", self.few_shot_example),
            ("æ€ç»´é“¾(CoT)", self.chain_of_thought_example),
            ("è‡ªæˆ‘åæ€", self.self_reflection_example),
            ("ç»“æ„åŒ–è¾“å‡º", self.structured_output_example)
        ]
        
        for name, method in techniques:
            print(f"\nğŸ” {name}:")
            print("-" * 40)
            result = method(text)
            print(result)
            print("-" * 40)
    
    def marketing_demo(self, product_description: str):
        """è¥é”€æ–‡æ¡ˆç”Ÿæˆç¤ºä¾‹"""
        print("\nğŸ“¢ è¥é”€æ–‡æ¡ˆç”Ÿæˆç¤ºä¾‹")
        print("=" * 60)
        print(f"ğŸ“ äº§å“æè¿°: {product_description}")
        print("=" * 60)
        
        result = self.role_playing_example(product_description)
        print(f"\nâœ¨ ç”Ÿæˆçš„è¥é”€æ–‡æ¡ˆ:")
        print(result)

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ LLM-101 æç¤ºè¯å·¥ç¨‹æŠ€å·§æ¼”ç¤º")
    print("=" * 60)
    
    try:
        demo = PromptEngineeringDemo()
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    # ç¤ºä¾‹æ–‡æœ¬
    sample_texts = [
        "ä»Šå¤©æ”¶åˆ°äº†æœŸå¾…å·²ä¹…çš„åŒ…è£¹ï¼Œæ‰“å¼€ä¸€çœ‹è´¨é‡è¶…å‡ºé¢„æœŸï¼Œéå¸¸æ»¡æ„ï¼",
        "è¿™å®¶é¤å…çš„æœåŠ¡æ€åº¦å¾ˆå·®ï¼Œé£Ÿç‰©ä¹Ÿä¸æ–°é²œï¼Œä¸ä¼šå†æ¥äº†ã€‚",
        "ä¼šè®®å®šäºæ˜å¤©ä¸Šåˆ9ç‚¹åœ¨ä¼šè®®å®¤ä¸¾è¡Œï¼Œè¯·å‡†æ—¶å‚åŠ ã€‚"
    ]
    
    # äº§å“æè¿°ç¤ºä¾‹
    product_sample = "æ™ºèƒ½è“ç‰™è€³æœºï¼Œæ”¯æŒä¸»åŠ¨é™å™ªï¼Œç»­èˆªæ—¶é—´é•¿è¾¾30å°æ—¶ï¼Œé‡‡ç”¨äººä½“å·¥å­¦è®¾è®¡ï¼Œä½©æˆ´èˆ’é€‚ã€‚"
    
    print("è¯·é€‰æ‹©æ¼”ç¤ºç±»å‹ï¼š")
    print("1. æƒ…æ„Ÿåˆ†ææŠ€å·§å¯¹æ¯”")
    print("2. è¥é”€æ–‡æ¡ˆç”Ÿæˆ")
    print("3. è‡ªå®šä¹‰æ–‡æœ¬åˆ†æ")
    
    choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-3): ").strip()
    
    if choice == "1":
        print("\né€‰æ‹©è¦åˆ†æçš„æ–‡æœ¬ï¼š")
        for i, text in enumerate(sample_texts, 1):
            print(f"{i}. {text}")
        
        text_choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-3): ").strip()
        try:
            selected_text = sample_texts[int(text_choice) - 1]
            demo.run_comparison(selected_text)
        except (ValueError, IndexError):
            print("âŒ æ— æ•ˆé€‰æ‹©")
    
    elif choice == "2":
        demo.marketing_demo(product_sample)
    
    elif choice == "3":
        custom_text = input("\nè¯·è¾“å…¥è¦åˆ†æçš„æ–‡æœ¬: ").strip()
        if custom_text:
            demo.run_comparison(custom_text)
        else:
            print("âŒ æ–‡æœ¬ä¸èƒ½ä¸ºç©º")
    
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")
    
    print("\nğŸ‰ æ¼”ç¤ºå®Œæˆï¼")
    print("ğŸ’¡ æç¤ºï¼šä¸åŒçš„æç¤ºè¯æŠ€å·§é€‚ç”¨äºä¸åŒçš„åœºæ™¯ï¼Œé€‰æ‹©åˆé€‚çš„æŠ€å·§å¯ä»¥æ˜¾è‘—æå‡æ•ˆæœã€‚")

if __name__ == "__main__":
    main() 
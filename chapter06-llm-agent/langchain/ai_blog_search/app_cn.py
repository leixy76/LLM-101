"""
AIåšå®¢æœç´¢ç³»ç»Ÿ - åŸºäºLangGraphçš„æ™ºèƒ½RAGåº”ç”¨

è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„æ™ºèƒ½æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)ç³»ç»Ÿï¼Œä½¿ç”¨LangChainå’ŒLangGraphæ„å»ºã€‚
ç³»ç»Ÿèƒ½å¤Ÿæ™ºèƒ½åœ°å¤„ç†ç”¨æˆ·æŸ¥è¯¢ï¼Œè‡ªåŠ¨å†³å®šæ˜¯å¦éœ€è¦æ£€ç´¢æ–‡æ¡£ã€é‡å†™æŸ¥è¯¢æˆ–ç›´æ¥ç”Ÿæˆç­”æ¡ˆã€‚

ä¸»è¦æŠ€æœ¯æ ˆï¼š
- LangChain: å¤§è¯­è¨€æ¨¡å‹åº”ç”¨å¼€å‘æ¡†æ¶
- LangGraph: çŠ¶æ€å›¾å·¥ä½œæµç®¡ç†
- Qdrant: å‘é‡æ•°æ®åº“
- Google Gemini: åµŒå…¥å’Œå¯¹è¯æ¨¡å‹
- Streamlit: Webç”¨æˆ·ç•Œé¢

ä½œè€…ï¼šAIå­¦ä¹ è€…ç¤¾åŒº
é€‚ç”¨å¯¹è±¡ï¼šå¤§æ¨¡å‹æŠ€æœ¯åˆå­¦è€…
"""

# å¯¼å…¥å¿…è¦çš„åº“å’Œæ¨¡å—
import streamlit as st  # Streamlitç”¨äºæ„å»ºWebç•Œé¢
from typing import Annotated, Literal, Sequence, TypedDict  # ç±»å‹æ³¨è§£
from uuid import uuid4  # ç”Ÿæˆå”¯ä¸€æ ‡è¯†ç¬¦
from functools import partial  # å‡½æ•°å¼ç¼–ç¨‹å·¥å…·

# LangChainæ ¸å¿ƒç»„ä»¶
from langchain_core.messages import BaseMessage, HumanMessage  # æ¶ˆæ¯ç±»å‹
from langchain_core.output_parsers import StrOutputParser  # è¾“å‡ºè§£æå™¨
from langchain_core.pydantic_v1 import BaseModel, Field  # æ•°æ®æ¨¡å‹

# LangChain Googleé›†æˆ
from langchain_google_genai import (
    ChatGoogleGenerativeAI,  # Googleå¯¹è¯æ¨¡å‹
    GoogleGenerativeAIEmbeddings  # GoogleåµŒå…¥æ¨¡å‹
)

# LangChainæ–‡æ¡£å¤„ç†
from langchain_community.document_loaders import WebBaseLoader  # ç½‘é¡µå†…å®¹åŠ è½½å™¨
from langchain_text_splitters import RecursiveCharacterTextSplitter  # æ–‡æ¡£åˆ†å‰²å™¨

# LangChain Qdranté›†æˆ
from langchain_qdrant import QdrantVectorStore  # Qdrantå‘é‡å­˜å‚¨
from qdrant_client import QdrantClient  # Qdrantå®¢æˆ·ç«¯

# LangGraphå·¥ä½œæµç»„ä»¶
from langgraph.graph import StateGraph, START, END  # çŠ¶æ€å›¾æ„å»º
from langgraph.graph.message import add_messages  # æ¶ˆæ¯å¤„ç†
from langgraph.prebuilt import tools_condition, ToolNode  # é¢„æ„å»ºå·¥å…·

# LangChain Hubç”¨äºè·å–é¢„å®šä¹‰æç¤ºæ¨¡æ¿
from langchain import hub

# è®¾ç½®Streamlité¡µé¢é…ç½®
st.set_page_config(
    page_title="AIåšå®¢æ™ºèƒ½æœç´¢ç³»ç»Ÿ",  # é¡µé¢æ ‡é¢˜
    page_icon="ğŸ¤–",  # é¡µé¢å›¾æ ‡
    layout="wide"  # å®½å±å¸ƒå±€
)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€å˜é‡
# Streamlitä½¿ç”¨session_stateæ¥åœ¨é¡µé¢åˆ·æ–°é—´ä¿æŒæ•°æ®
if 'qdrant_host' not in st.session_state:
    st.session_state.qdrant_host = ""
if 'qdrant_api_key' not in st.session_state:
    st.session_state.qdrant_api_key = ""
if 'gemini_api_key' not in st.session_state:
    st.session_state.gemini_api_key = ""


def set_sidebar():
    """
    è®¾ç½®ä¾§è¾¹æ ç”¨äºAPIå¯†é’¥å’Œé…ç½®ç®¡ç†
    
    è¿™ä¸ªå‡½æ•°åˆ›å»ºä¸€ä¸ªä¾§è¾¹æ ç•Œé¢ï¼Œè®©ç”¨æˆ·è¾“å…¥å¿…è¦çš„APIé…ç½®ä¿¡æ¯ï¼š
    - Qdrantæ•°æ®åº“ä¸»æœºåœ°å€
    - Qdrant APIå¯†é’¥
    - Google Gemini APIå¯†é’¥
    
    æ‰€æœ‰è¾“å…¥éƒ½ä½¿ç”¨passwordç±»å‹ä»¥ä¿æŠ¤æ•æ„Ÿä¿¡æ¯
    """
    with st.sidebar:
        st.subheader("ğŸ”§ APIé…ç½®")
        
        # è¾“å…¥æ¡†ä½¿ç”¨passwordç±»å‹éšè—æ•æ„Ÿä¿¡æ¯
        qdrant_host = st.text_input(
            "è¾“å…¥Qdrantä¸»æœºURL:", 
            type="password",
            help="ä¾‹å¦‚: https://your-cluster.qdrant.io"
        )
        qdrant_api_key = st.text_input(
            "è¾“å…¥Qdrant APIå¯†é’¥:", 
            type="password",
            help="ä»Qdrantæ§åˆ¶å°è·å–çš„APIå¯†é’¥"
        )
        gemini_api_key = st.text_input(
            "è¾“å…¥Gemini APIå¯†é’¥:", 
            type="password",
            help="ä»Google AI Studioè·å–çš„APIå¯†é’¥"
        )

        # é…ç½®å®ŒæˆæŒ‰é’®
        if st.button("âœ… å®Œæˆé…ç½®"):
            if qdrant_host and qdrant_api_key and gemini_api_key:
                # ä¿å­˜é…ç½®åˆ°ä¼šè¯çŠ¶æ€
                st.session_state.qdrant_host = qdrant_host
                st.session_state.qdrant_api_key = qdrant_api_key
                st.session_state.gemini_api_key = gemini_api_key
                st.success("ğŸ‰ APIå¯†é’¥é…ç½®æˆåŠŸï¼")
            else:
                st.warning("âš ï¸ è¯·å¡«å†™æ‰€æœ‰APIé…ç½®å­—æ®µ")


def initialize_components():
    """
    åˆå§‹åŒ–éœ€è¦APIå¯†é’¥çš„æ ¸å¿ƒç»„ä»¶
    
    è¿™ä¸ªå‡½æ•°è´Ÿè´£åˆå§‹åŒ–æ•´ä¸ªRAGç³»ç»Ÿçš„æ ¸å¿ƒç»„ä»¶ï¼š
    1. GoogleåµŒå…¥æ¨¡å‹ - ç”¨äºå°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡
    2. Qdrantå®¢æˆ·ç«¯ - ç”¨äºå‘é‡æ•°æ®åº“æ“ä½œ
    3. å‘é‡å­˜å‚¨ - ç”¨äºå­˜å‚¨å’Œæ£€ç´¢æ–‡æ¡£å‘é‡
    
    Returns:
        tuple: (åµŒå…¥æ¨¡å‹, Qdrantå®¢æˆ·ç«¯, å‘é‡å­˜å‚¨) æˆ– (None, None, None)
    """
    # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å¿…éœ€çš„APIå¯†é’¥éƒ½å·²é…ç½®
    if not all([
        st.session_state.qdrant_host, 
        st.session_state.qdrant_api_key, 
        st.session_state.gemini_api_key
    ]):
        return None, None, None

    try:
        # åˆå§‹åŒ–GoogleåµŒå…¥æ¨¡å‹
        # embedding-001æ˜¯Googleä¸“é—¨ç”¨äºæ–‡æœ¬åµŒå…¥çš„æ¨¡å‹
        embedding_model = GoogleGenerativeAIEmbeddings(
            model="models/embedding-001",
            google_api_key=st.session_state.gemini_api_key
        )

        # åˆå§‹åŒ–Qdrantå®¢æˆ·ç«¯
        # Qdrantæ˜¯ä¸€ä¸ªé«˜æ€§èƒ½çš„å‘é‡æœç´¢å¼•æ“
        client = QdrantClient(
            st.session_state.qdrant_host,
            api_key=st.session_state.qdrant_api_key
        )

        # åˆå§‹åŒ–å‘é‡å­˜å‚¨
        # è¿™æ˜¯LangChainå¯¹Qdrantçš„å°è£…ï¼Œæä¾›äº†ä¾¿æ·çš„æ–‡æ¡£æ“ä½œæ¥å£
        db = QdrantVectorStore(
            client=client,
            collection_name="qdrant_db",  # é›†åˆåç§°
            embedding=embedding_model     # åµŒå…¥æ¨¡å‹
        )

        return embedding_model, client, db
        
    except Exception as e:
        st.error(f"âŒ ç»„ä»¶åˆå§‹åŒ–é”™è¯¯: {str(e)}")
        return None, None, None


class AgentState(TypedDict):
    """
    AgentçŠ¶æ€å®šä¹‰
    
    è¿™ä¸ªç±»å®šä¹‰äº†åœ¨æ•´ä¸ªLangGraphå·¥ä½œæµä¸­ä¼ é€’çš„çŠ¶æ€ä¿¡æ¯ã€‚
    ä½¿ç”¨TypedDictç¡®ä¿ç±»å‹å®‰å…¨ï¼ŒAnnotatedæä¾›é¢å¤–çš„å…ƒæ•°æ®ã€‚
    
    Attributes:
        messages: å¯¹è¯æ¶ˆæ¯åºåˆ—ï¼Œä½¿ç”¨add_messageså‡½æ•°å¤„ç†æ¶ˆæ¯æ·»åŠ 
    """
    messages: Annotated[Sequence[BaseMessage], add_messages]


def grade_documents(state) -> Literal["generate", "rewrite"]:
    """
    æ–‡æ¡£ç›¸å…³æ€§è¯„åˆ†å‡½æ•°
    
    è¿™æ˜¯RAGç³»ç»Ÿçš„æ ¸å¿ƒç»„ä»¶ä¹‹ä¸€ï¼Œè´Ÿè´£è¯„ä¼°æ£€ç´¢åˆ°çš„æ–‡æ¡£æ˜¯å¦ä¸ç”¨æˆ·æŸ¥è¯¢ç›¸å…³ã€‚
    åŸºäºè¯„åˆ†ç»“æœï¼Œç³»ç»Ÿä¼šå†³å®šæ˜¯ç”Ÿæˆç­”æ¡ˆè¿˜æ˜¯é‡å†™æŸ¥è¯¢ã€‚
    
    å·¥ä½œæµç¨‹ï¼š
    1. æå–ç”¨æˆ·çš„åŸå§‹é—®é¢˜
    2. è·å–æœ€åæ£€ç´¢åˆ°çš„æ–‡æ¡£å†…å®¹
    3. ä½¿ç”¨Geminiæ¨¡å‹è¯„ä¼°ç›¸å…³æ€§
    4. è¿”å›å†³ç­–ç»“æœ
    
    Args:
        state: åŒ…å«æ¶ˆæ¯å†å²çš„çŠ¶æ€å¯¹è±¡
        
    Returns:
        Literal["generate", "rewrite"]: "generate"è¡¨ç¤ºç”Ÿæˆç­”æ¡ˆï¼Œ"rewrite"è¡¨ç¤ºé‡å†™æŸ¥è¯¢
    """
    print("---æ‰§è¡Œæ–‡æ¡£ç›¸å…³æ€§è¯„åˆ†---")
    
    # ä»çŠ¶æ€ä¸­æå–æ¶ˆæ¯
    messages = state["messages"]
    last_message = messages[-1]  # è·å–æœ€åä¸€æ¡æ¶ˆæ¯ï¼ˆæ£€ç´¢åˆ°çš„æ–‡æ¡£ï¼‰
    question = messages[0].content  # è·å–åŸå§‹ç”¨æˆ·é—®é¢˜
    docs = last_message.content  # è·å–æ–‡æ¡£å†…å®¹

    # å®šä¹‰è¯„åˆ†æ¨¡å‹çš„è¾“å‡ºæ ¼å¼
    class grade(BaseModel):
        """
        ç›¸å…³æ€§è¯„åˆ†çš„äºŒå…ƒåˆ†ç±»æ¨¡å‹
        
        è¿™ä¸ªæ¨¡å‹ç¡®ä¿Geminiçš„è¾“å‡ºæ ¼å¼æ ‡å‡†åŒ–ï¼Œåªè¿”å›'yes'æˆ–'no'
        """
        binary_score: str = Field(
            description="ç›¸å…³æ€§è¯„åˆ†ç»“æœï¼š'yes'è¡¨ç¤ºç›¸å…³ï¼Œ'no'è¡¨ç¤ºä¸ç›¸å…³"
        )

    # åˆå§‹åŒ–å¸¦æœ‰ç»“æ„åŒ–è¾“å‡ºçš„Geminiæ¨¡å‹
    model = ChatGoogleGenerativeAI(
        api_key=st.session_state.gemini_api_key,
        temperature=0,  # è®¾ç½®ä¸º0ç¡®ä¿è¾“å‡ºä¸€è‡´æ€§
        model="gemini-2.0-flash"
    )
    
    # ç»‘å®šè¾“å‡ºæ ¼å¼
    llm_with_tool = model.with_structured_output(grade)

    # æ„å»ºè¯„åˆ†æç¤º
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªæ–‡æ¡£ç›¸å…³æ€§è¯„ä¼°ä¸“å®¶ã€‚è¯·è¯„ä¼°æ£€ç´¢åˆ°çš„æ–‡æ¡£æ˜¯å¦ä¸ç”¨æˆ·é—®é¢˜ç›¸å…³ã€‚

    ç”¨æˆ·é—®é¢˜: {question}
    
    æ£€ç´¢åˆ°çš„æ–‡æ¡£: {docs}
    
    è¯„ä¼°æ ‡å‡†ï¼š
    1. æ–‡æ¡£å†…å®¹æ˜¯å¦ç›´æ¥å›ç­”äº†ç”¨æˆ·çš„é—®é¢˜ï¼Ÿ
    2. æ–‡æ¡£ä¸­æ˜¯å¦åŒ…å«ä¸é—®é¢˜ç›¸å…³çš„å…³é”®ä¿¡æ¯ï¼Ÿ
    3. æ–‡æ¡£çš„ä¸»é¢˜æ˜¯å¦ä¸é—®é¢˜çš„ä¸»é¢˜ä¸€è‡´ï¼Ÿ
    
    å¦‚æœæ–‡æ¡£ç›¸å…³ä¸”æœ‰ç”¨ï¼Œè¯·è¿”å›'yes'ï¼›å¦‚æœä¸ç›¸å…³æˆ–æ— ç”¨ï¼Œè¯·è¿”å›'no'ã€‚
    """

    # æ‰§è¡Œè¯„åˆ†
    res = llm_with_tool.invoke([HumanMessage(content=prompt)])
    
    # æ ¹æ®è¯„åˆ†ç»“æœè¿”å›ä¸‹ä¸€æ­¥åŠ¨ä½œ
    if res.binary_score == "yes":
        print("---æ–‡æ¡£ç›¸å…³ï¼Œå‡†å¤‡ç”Ÿæˆç­”æ¡ˆ---")
        return "generate"
    else:
        print("---æ–‡æ¡£ä¸ç›¸å…³ï¼Œéœ€è¦é‡å†™æŸ¥è¯¢---")
        return "rewrite"


def agent(state, tools):
    """
    æ ¸å¿ƒAgentå†³ç­–å‡½æ•°
    
    è¿™æ˜¯æ•´ä¸ªç³»ç»Ÿçš„"å¤§è„‘"ï¼Œè´Ÿè´£åˆ†æç”¨æˆ·æŸ¥è¯¢å¹¶å†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨ã€‚
    Agentä¼šæ ¹æ®å½“å‰çŠ¶æ€å’Œå¯ç”¨å·¥å…·æ¥åšå‡ºæ™ºèƒ½å†³ç­–ã€‚
    
    å†³ç­–é€»è¾‘ï¼š
    1. åˆ†æç”¨æˆ·æŸ¥è¯¢çš„å¤æ‚åº¦å’Œç±»å‹
    2. å†³å®šæ˜¯å¦éœ€è¦ä½¿ç”¨æ£€ç´¢å·¥å…·
    3. å¦‚æœæŸ¥è¯¢ç®€å•æ˜ç¡®ï¼Œå¯èƒ½ç›´æ¥ç»“æŸå¯¹è¯
    4. å¦‚æœéœ€è¦æ›´å¤šä¿¡æ¯ï¼Œä¼šè°ƒç”¨æ£€ç´¢å·¥å…·
    
    Args:
        state: å½“å‰å¯¹è¯çŠ¶æ€
        tools: å¯ç”¨çš„å·¥å…·åˆ—è¡¨ï¼ˆä¸»è¦æ˜¯æ£€ç´¢å·¥å…·ï¼‰
        
    Returns:
        dict: åŒ…å«Agentå“åº”æ¶ˆæ¯çš„çŠ¶æ€æ›´æ–°
    """
    print("---è°ƒç”¨Agentè¿›è¡Œå†³ç­–---")
    
    # è·å–å¯¹è¯å†å²
    messages = state["messages"]
    
    # åˆå§‹åŒ–Geminiå¯¹è¯æ¨¡å‹
    # ä½¿ç”¨æµå¼è¾“å‡ºæå‡ç”¨æˆ·ä½“éªŒ
    model = ChatGoogleGenerativeAI(
        api_key=st.session_state.gemini_api_key, 
        temperature=0,  # ç¡®ä¿è¾“å‡ºä¸€è‡´æ€§
        streaming=True,  # å¯ç”¨æµå¼è¾“å‡º
        model="gemini-2.0-flash"
    )
    
    # ç»‘å®šå¯ç”¨å·¥å…·
    model = model.bind_tools(tools)
    
    # è°ƒç”¨æ¨¡å‹ç”Ÿæˆå“åº”
    response = model.invoke(messages)
    
    # è¿”å›çŠ¶æ€æ›´æ–°ï¼ˆæ·»åŠ Agentçš„å“åº”åˆ°æ¶ˆæ¯åˆ—è¡¨ï¼‰
    return {"messages": [response]}


def rewrite(state):
    """
    æŸ¥è¯¢é‡å†™å‡½æ•°
    
    å½“æ£€ç´¢åˆ°çš„æ–‡æ¡£ä¸ç”¨æˆ·æŸ¥è¯¢ä¸å¤Ÿç›¸å…³æ—¶ï¼Œè¿™ä¸ªå‡½æ•°ä¼šè¢«è°ƒç”¨æ¥é‡å†™æŸ¥è¯¢ã€‚
    é‡å†™çš„ç›®æ ‡æ˜¯ç”Ÿæˆä¸€ä¸ªæ›´ç²¾ç¡®ã€æ›´å®¹æ˜“æ£€ç´¢åˆ°ç›¸å…³æ–‡æ¡£çš„æŸ¥è¯¢ã€‚
    
    é‡å†™ç­–ç•¥ï¼š
    1. åˆ†æåŸå§‹æŸ¥è¯¢çš„è¯­ä¹‰æ„å›¾
    2. è¯†åˆ«å…³é”®æ¦‚å¿µå’Œå®ä½“
    3. é‡æ–°ç»„ç»‡è¯­è¨€è¡¨è¾¾
    4. ç”Ÿæˆæ›´ç²¾ç¡®çš„æŸ¥è¯¢è¯­å¥
    
    Args:
        state: åŒ…å«å¯¹è¯å†å²çš„çŠ¶æ€
        
    Returns:
        dict: åŒ…å«é‡å†™åæŸ¥è¯¢çš„çŠ¶æ€æ›´æ–°
    """
    print("---æ‰§è¡ŒæŸ¥è¯¢é‡å†™---")
    
    # æå–æ¶ˆæ¯å’ŒåŸå§‹é—®é¢˜
    messages = state["messages"]
    question = messages[0].content

    # æ„å»ºé‡å†™æç¤ºæ¶ˆæ¯
    msg = [
        HumanMessage(
            content=f"""
            è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·æŸ¥è¯¢ï¼Œç†è§£å…¶æ½œåœ¨çš„è¯­ä¹‰æ„å›¾å’Œå«ä¹‰ã€‚
            
            åŸå§‹æŸ¥è¯¢:
            ------- 
            {question} 
            -------
            
            è¯·æ‰§è¡Œä»¥ä¸‹ä»»åŠ¡ï¼š
            1. åˆ†ææŸ¥è¯¢çš„æ ¸å¿ƒæ„å›¾å’Œå…³é”®æ¦‚å¿µ
            2. è¯†åˆ«å¯èƒ½å½±å“æ£€ç´¢æ•ˆæœçš„æ¨¡ç³Šè¡¨è¾¾
            3. é‡æ–°ç»„ç»‡è¯­è¨€ï¼Œä½¿å…¶æ›´åŠ ç²¾ç¡®å’Œå…·ä½“
            4. ç”Ÿæˆä¸€ä¸ªæ”¹è¿›çš„æŸ¥è¯¢è¯­å¥
            
            æ”¹è¿›åçš„æŸ¥è¯¢åº”è¯¥ï¼š
            - æ›´åŠ å…·ä½“å’Œæ˜ç¡®
            - åŒ…å«ç›¸å…³çš„å…³é”®è¯
            - æ˜“äºåŒ¹é…ç›¸å…³æ–‡æ¡£
            
            è¯·ç›´æ¥æä¾›æ”¹è¿›åçš„æŸ¥è¯¢è¯­å¥ï¼š
            """,
        )
    ]

    # ä½¿ç”¨Geminiæ¨¡å‹è¿›è¡ŒæŸ¥è¯¢é‡å†™
    model = ChatGoogleGenerativeAI(
        api_key=st.session_state.gemini_api_key, 
        temperature=0, 
        model="gemini-2.0-flash", 
        streaming=True
    )
    
    # ç”Ÿæˆé‡å†™åçš„æŸ¥è¯¢
    response = model.invoke(msg)
    
    return {"messages": [response]}


def generate(state):
    """
    ç­”æ¡ˆç”Ÿæˆå‡½æ•°
    
    è¿™æ˜¯RAGæµç¨‹çš„æœ€åä¸€æ­¥ï¼ŒåŸºäºæ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æ¡£ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆã€‚
    ä½¿ç”¨æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)æ¨¡å¼ï¼Œç¡®ä¿ç­”æ¡ˆåŸºäºå®é™…æ–‡æ¡£å†…å®¹ã€‚
    
    RAGç”Ÿæˆæµç¨‹ï¼š
    1. æå–ç”¨æˆ·åŸå§‹é—®é¢˜
    2. è·å–æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æ¡£
    3. ä½¿ç”¨é¢„å®šä¹‰çš„RAGæç¤ºæ¨¡æ¿
    4. ç»“åˆæ–‡æ¡£å†…å®¹ç”Ÿæˆå‡†ç¡®ç­”æ¡ˆ
    
    Args:
        state: åŒ…å«é—®é¢˜å’Œæ–‡æ¡£çš„çŠ¶æ€
        
    Returns:
        dict: åŒ…å«ç”Ÿæˆç­”æ¡ˆçš„çŠ¶æ€æ›´æ–°
    """
    print("---ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ---")
    
    # æå–æ¶ˆæ¯ã€é—®é¢˜å’Œæ–‡æ¡£
    messages = state["messages"]
    question = messages[0].content  # åŸå§‹ç”¨æˆ·é—®é¢˜
    last_message = messages[-1]     # æœ€åä¸€æ¡æ¶ˆæ¯ï¼ˆæ£€ç´¢åˆ°çš„æ–‡æ¡£ï¼‰
    docs = last_message.content     # æ–‡æ¡£å†…å®¹

    # ä»LangChain Hubè·å–é¢„å®šä¹‰çš„RAGæç¤ºæ¨¡æ¿
    # è¿™ä¸ªæ¨¡æ¿ç»è¿‡ä¼˜åŒ–ï¼Œèƒ½å¤Ÿæœ‰æ•ˆç»“åˆé—®é¢˜å’Œæ–‡æ¡£ç”Ÿæˆç­”æ¡ˆ
    prompt_template = hub.pull("rlm/rag-prompt")

    # åˆå§‹åŒ–å¯¹è¯æ¨¡å‹
    chat_model = ChatGoogleGenerativeAI(
        api_key=st.session_state.gemini_api_key, 
        model="gemini-2.0-flash", 
        temperature=0,  # ç¡®ä¿ç­”æ¡ˆä¸€è‡´æ€§
        streaming=True  # æµå¼è¾“å‡º
    )

    # åˆå§‹åŒ–è¾“å‡ºè§£æå™¨
    # å°†æ¨¡å‹è¾“å‡ºè½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼
    output_parser = StrOutputParser()
    
    # æ„å»ºRAGå¤„ç†é“¾
    # æç¤ºæ¨¡æ¿ -> å¯¹è¯æ¨¡å‹ -> è¾“å‡ºè§£æå™¨
    rag_chain = prompt_template | chat_model | output_parser

    # æ‰§è¡ŒRAGç”Ÿæˆ
    # context: æ£€ç´¢åˆ°çš„æ–‡æ¡£å†…å®¹
    # question: ç”¨æˆ·çš„åŸå§‹é—®é¢˜
    response = rag_chain.invoke({"context": docs, "question": question})
    
    return {"messages": [response]}


def get_graph(retriever_tool):
    """
    æ„å»ºLangGraphå·¥ä½œæµå›¾
    
    è¿™ä¸ªå‡½æ•°åˆ›å»ºæ•´ä¸ªRAGç³»ç»Ÿçš„å·¥ä½œæµç¨‹å›¾ï¼Œå®šä¹‰äº†å„ä¸ªç»„ä»¶ä¹‹é—´çš„è¿æ¥å…³ç³»ã€‚
    å·¥ä½œæµå›¾æ˜¯ä¸€ä¸ªæœ‰å‘å›¾ï¼ŒèŠ‚ç‚¹ä»£è¡¨å¤„ç†æ­¥éª¤ï¼Œè¾¹ä»£è¡¨æ•°æ®æµå‘ã€‚
    
    å·¥ä½œæµç¨‹ï¼š
    1. ç”¨æˆ·æŸ¥è¯¢ -> Agentå†³ç­–
    2. Agentå†³ç­– -> æ£€ç´¢å·¥å…· æˆ– ç›´æ¥ç»“æŸ
    3. æ£€ç´¢ç»“æœ -> æ–‡æ¡£è¯„åˆ†
    4. æ–‡æ¡£è¯„åˆ† -> ç”Ÿæˆç­”æ¡ˆ æˆ– é‡å†™æŸ¥è¯¢
    5. é‡å†™æŸ¥è¯¢ -> å›åˆ°Agentå†³ç­–
    6. ç”Ÿæˆç­”æ¡ˆ -> ç»“æŸ
    
    Args:
        retriever_tool: æ–‡æ¡£æ£€ç´¢å·¥å…·
        
    Returns:
        CompiledGraph: ç¼–è¯‘åçš„å·¥ä½œæµå›¾
    """
    # åˆ›å»ºå·¥å…·åˆ—è¡¨
    tools = [retriever_tool]
    
    # å®šä¹‰çŠ¶æ€å›¾ï¼Œä½¿ç”¨AgentStateä½œä¸ºçŠ¶æ€ç±»å‹
    workflow = StateGraph(AgentState)

    # æ·»åŠ AgentèŠ‚ç‚¹
    # ä½¿ç”¨partialå‡½æ•°å°†toolså‚æ•°ç»‘å®šåˆ°agentå‡½æ•°
    workflow.add_node("agent", partial(agent, tools=tools))
    
    # æ·»åŠ æ£€ç´¢èŠ‚ç‚¹
    # ToolNodeæ˜¯LangGraphé¢„æ„å»ºçš„å·¥å…·æ‰§è¡ŒèŠ‚ç‚¹
    retrieve = ToolNode(tools)
    workflow.add_node("retrieve", retrieve)
    
    # æ·»åŠ æŸ¥è¯¢é‡å†™èŠ‚ç‚¹
    workflow.add_node("rewrite", rewrite)
    
    # æ·»åŠ ç­”æ¡ˆç”ŸæˆèŠ‚ç‚¹
    workflow.add_node("generate", generate)

    # å®šä¹‰å·¥ä½œæµçš„èµ·å§‹ç‚¹
    # æ‰€æœ‰å¯¹è¯éƒ½ä»AgentèŠ‚ç‚¹å¼€å§‹
    workflow.add_edge(START, "agent")

    # æ·»åŠ AgentèŠ‚ç‚¹çš„æ¡ä»¶è¾¹
    # tools_conditionæ˜¯é¢„æ„å»ºçš„æ¡ä»¶å‡½æ•°ï¼Œç”¨äºåˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
    workflow.add_conditional_edges(
        "agent",
        tools_condition,  # æ¡ä»¶åˆ¤æ–­å‡½æ•°
        {
            "tools": "retrieve",  # å¦‚æœéœ€è¦å·¥å…·ï¼Œè½¬åˆ°æ£€ç´¢èŠ‚ç‚¹
            END: END,            # å¦‚æœä¸éœ€è¦å·¥å…·ï¼Œç›´æ¥ç»“æŸ
        },
    )

    # æ·»åŠ æ£€ç´¢èŠ‚ç‚¹çš„æ¡ä»¶è¾¹
    # æ£€ç´¢å®Œæˆåï¼Œéœ€è¦è¯„ä¼°æ–‡æ¡£ç›¸å…³æ€§
    workflow.add_conditional_edges(
        "retrieve",
        grade_documents,  # æ–‡æ¡£è¯„åˆ†å‡½æ•°
        # æ ¹æ®è¯„åˆ†ç»“æœå†³å®šä¸‹ä¸€æ­¥ï¼š
        # "generate": ç”Ÿæˆç­”æ¡ˆ
        # "rewrite": é‡å†™æŸ¥è¯¢
    )
    
    # æ·»åŠ å›ºå®šè¾¹
    workflow.add_edge("generate", END)    # ç”Ÿæˆç­”æ¡ˆåç»“æŸ
    workflow.add_edge("rewrite", "agent") # é‡å†™æŸ¥è¯¢åå›åˆ°Agent

    # ç¼–è¯‘å·¥ä½œæµå›¾
    # ç¼–è¯‘è¿‡ç¨‹ä¼šéªŒè¯å›¾çš„å®Œæ•´æ€§å’Œæ­£ç¡®æ€§
    graph = workflow.compile()

    return graph


def generate_message(graph, inputs):
    """
    æ‰§è¡Œå·¥ä½œæµå¹¶ç”Ÿæˆæœ€ç»ˆæ¶ˆæ¯
    
    è¿™ä¸ªå‡½æ•°æ‰§è¡Œæ•´ä¸ªLangGraphå·¥ä½œæµï¼Œå¹¶æå–æœ€ç»ˆç”Ÿæˆçš„ç­”æ¡ˆã€‚
    å®ƒä¼šéå†å·¥ä½œæµçš„æ‰€æœ‰è¾“å‡ºï¼Œæ‰¾åˆ°æœ€ç»ˆçš„ç”Ÿæˆç»“æœã€‚
    
    Args:
        graph: ç¼–è¯‘åçš„å·¥ä½œæµå›¾
        inputs: è¾“å…¥æ•°æ®ï¼ˆåŒ…å«ç”¨æˆ·æŸ¥è¯¢ï¼‰
        
    Returns:
        str: ç”Ÿæˆçš„æœ€ç»ˆç­”æ¡ˆ
    """
    generated_message = ""

    # æµå¼æ‰§è¡Œå·¥ä½œæµå›¾
    # graph.stream()ä¼šé€æ­¥æ‰§è¡Œå·¥ä½œæµçš„æ¯ä¸ªèŠ‚ç‚¹
    for output in graph.stream(inputs):
        for key, value in output.items():
            # æŸ¥æ‰¾ç”ŸæˆèŠ‚ç‚¹çš„è¾“å‡º
            if key == "generate" and isinstance(value, dict):
                # æå–ç”Ÿæˆçš„æ¶ˆæ¯
                generated_message = value.get("messages", [""])[0]
    
    return generated_message


def add_documents_to_qdrant(url, db):
    """
    å°†ç½‘é¡µæ–‡æ¡£æ·»åŠ åˆ°Qdrantå‘é‡æ•°æ®åº“
    
    è¿™ä¸ªå‡½æ•°å®ç°äº†å®Œæ•´çš„æ–‡æ¡£å¤„ç†æµç¨‹ï¼š
    1. ä»URLåŠ è½½ç½‘é¡µå†…å®¹
    2. å°†é•¿æ–‡æ¡£åˆ†å‰²æˆå°å—
    3. ä¸ºæ¯ä¸ªæ–‡æ¡£å—ç”Ÿæˆå”¯ä¸€ID
    4. å°†æ–‡æ¡£å—å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
    
    æ–‡æ¡£åˆ†å—çš„é‡è¦æ€§ï¼š
    - æé«˜æ£€ç´¢ç²¾åº¦ï¼šå°å—æ›´å®¹æ˜“åŒ¹é…ç‰¹å®šæŸ¥è¯¢
    - æ§åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦ï¼šé¿å…è¶…å‡ºæ¨¡å‹è¾“å…¥é™åˆ¶
    - æå‡æ£€ç´¢æ•ˆç‡ï¼šå‡å°‘æ— å…³ä¿¡æ¯çš„å¹²æ‰°
    
    Args:
        url (str): è¦å¤„ç†çš„ç½‘é¡µURL
        db: Qdrantå‘é‡å­˜å‚¨å®ä¾‹
        
    Returns:
        bool: å¤„ç†æˆåŠŸè¿”å›Trueï¼Œå¤±è´¥è¿”å›False
    """
    try:
        # ä½¿ç”¨WebBaseLoaderåŠ è½½ç½‘é¡µå†…å®¹
        # WebBaseLoaderèƒ½å¤Ÿå¤„ç†å„ç§ç½‘é¡µæ ¼å¼ï¼Œæå–ä¸»è¦æ–‡æœ¬å†…å®¹
        docs = WebBaseLoader(url).load()
        
        # åˆå§‹åŒ–æ–‡æ¡£åˆ†å‰²å™¨
        # RecursiveCharacterTextSplitterä½¿ç”¨é€’å½’æ–¹æ³•æ™ºèƒ½åˆ†å‰²æ–‡æ¡£
        text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
            chunk_size=100,    # æ¯ä¸ªå—çš„æœ€å¤§å­—ç¬¦æ•°
            chunk_overlap=50   # å—ä¹‹é—´çš„é‡å å­—ç¬¦æ•°ï¼Œä¿æŒä¸Šä¸‹æ–‡è¿ç»­æ€§
        )
        
        # æ‰§è¡Œæ–‡æ¡£åˆ†å‰²
        doc_chunks = text_splitter.split_documents(docs)
        
        # ä¸ºæ¯ä¸ªæ–‡æ¡£å—ç”Ÿæˆå”¯ä¸€æ ‡è¯†ç¬¦
        # UUIDç¡®ä¿æ¯ä¸ªæ–‡æ¡£å—éƒ½æœ‰å”¯ä¸€çš„ID
        uuids = [str(uuid4()) for _ in range(len(doc_chunks))]
        
        # å°†æ–‡æ¡£å—æ·»åŠ åˆ°å‘é‡æ•°æ®åº“
        # è¿™ä¸ªè¿‡ç¨‹åŒ…æ‹¬ï¼š
        # 1. ä½¿ç”¨åµŒå…¥æ¨¡å‹å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡
        # 2. å°†å‘é‡å’Œå…ƒæ•°æ®å­˜å‚¨åˆ°Qdrant
        db.add_documents(documents=doc_chunks, ids=uuids)
        
        return True
        
    except Exception as e:
        # é”™è¯¯å¤„ç†ï¼šæ˜¾ç¤ºå…·ä½“é”™è¯¯ä¿¡æ¯
        st.error(f"âŒ æ–‡æ¡£æ·»åŠ é”™è¯¯: {str(e)}")
        return False


def main():
    """
    ä¸»å‡½æ•° - Streamlitåº”ç”¨çš„å…¥å£ç‚¹
    
    è¿™ä¸ªå‡½æ•°åè°ƒæ•´ä¸ªåº”ç”¨çš„ç”¨æˆ·ç•Œé¢å’Œæ ¸å¿ƒåŠŸèƒ½ï¼š
    1. è®¾ç½®é¡µé¢æ ‡é¢˜å’Œè¯´æ˜
    2. ç®¡ç†APIé…ç½®
    3. åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶
    4. å¤„ç†æ–‡æ¡£æ·»åŠ 
    5. æ‰§è¡Œæ™ºèƒ½é—®ç­”
    
    ç”¨æˆ·äº¤äº’æµç¨‹ï¼š
    1. é…ç½®APIå¯†é’¥
    2. æ·»åŠ åšå®¢URL
    3. è¾“å…¥é—®é¢˜
    4. è·å–æ™ºèƒ½ç­”æ¡ˆ
    """
    # é¡µé¢æ ‡é¢˜å’Œä»‹ç»
    st.title("ğŸ¤– AIåšå®¢æ™ºèƒ½æœç´¢ç³»ç»Ÿ")
    st.markdown("""
    ### åŸºäºLangGraphçš„æ™ºèƒ½RAGç³»ç»Ÿ
    
    è¿™æ˜¯ä¸€ä¸ªæ™ºèƒ½çš„åšå®¢æœç´¢ç³»ç»Ÿï¼Œèƒ½å¤Ÿï¼š
    - ğŸ“š **æ™ºèƒ½æ–‡æ¡£å¤„ç†**ï¼šè‡ªåŠ¨æŠ“å–å’Œåˆ†æåšå®¢å†…å®¹
    - ğŸ§  **æ™ºèƒ½æŸ¥è¯¢ç†è§£**ï¼šç†è§£ç”¨æˆ·æ„å›¾ï¼Œè‡ªåŠ¨ä¼˜åŒ–æŸ¥è¯¢
    - ğŸ” **ç²¾å‡†ä¿¡æ¯æ£€ç´¢**ï¼šåŸºäºå‘é‡ç›¸ä¼¼åº¦çš„è¯­ä¹‰æœç´¢
    - ğŸ’¬ **æ™ºèƒ½ç­”æ¡ˆç”Ÿæˆ**ï¼šç»“åˆæ£€ç´¢å†…å®¹ç”Ÿæˆå‡†ç¡®ç­”æ¡ˆ
    
    ---
    """)
    
    # è®¾ç½®ä¾§è¾¹æ é…ç½®
    set_sidebar()
    
    # åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶
    embedding_model, client, db = initialize_components()
    
    # æ£€æŸ¥ç»„ä»¶æ˜¯å¦æˆåŠŸåˆå§‹åŒ–
    if not all([embedding_model, client, db]):
        st.warning("âš ï¸ è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½®æ‰€æœ‰å¿…éœ€çš„APIå¯†é’¥")
        st.info("""
        ### ğŸ”§ é…ç½®è¯´æ˜ï¼š
        
        1. **Qdranté…ç½®**ï¼š
           - æ³¨å†ŒQdrant Cloudè´¦æˆ·ï¼šhttps://qdrant.tech/
           - åˆ›å»ºé›†ç¾¤å¹¶è·å–URLå’ŒAPIå¯†é’¥
        
        2. **Google Geminié…ç½®**ï¼š
           - è®¿é—®Google AI Studioï¼šhttps://aistudio.google.com/
           - åˆ›å»ºAPIå¯†é’¥
        
        3. **é…ç½®å®Œæˆå**ï¼š
           - ç‚¹å‡»"å®Œæˆé…ç½®"æŒ‰é’®
           - å¼€å§‹ä½¿ç”¨ç³»ç»ŸåŠŸèƒ½
        """)
        return
    
    # åˆ›å»ºæ£€ç´¢å·¥å…·
    # è¿™æ˜¯Agentå¯ä»¥è°ƒç”¨çš„å·¥å…·ï¼Œç”¨äºä»å‘é‡æ•°æ®åº“æ£€ç´¢ç›¸å…³æ–‡æ¡£
    retriever_tool = db.as_retriever().as_tool(
        name="blog_search",
        description="æœç´¢åšå®¢å†…å®¹ä»¥å›ç­”ç”¨æˆ·é—®é¢˜ã€‚è¾“å…¥åº”è¯¥æ˜¯ä¸€ä¸ªæœç´¢æŸ¥è¯¢ã€‚"
    )
    
    # æ„å»ºLangGraphå·¥ä½œæµ
    graph = get_graph(retriever_tool)
    
    # æ–‡æ¡£ç®¡ç†éƒ¨åˆ†
    st.subheader("ğŸ“„ æ–‡æ¡£ç®¡ç†")
    
    # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
    col1, col2 = st.columns([3, 1])
    
    with col1:
        # åšå®¢URLè¾“å…¥æ¡†
        blog_url = st.text_input(
            "è¾“å…¥åšå®¢æ–‡ç« URL:",
            placeholder="https://example.com/blog-post",
            help="è¾“å…¥æ‚¨æƒ³è¦åˆ†æçš„åšå®¢æ–‡ç« é“¾æ¥"
        )
    
    with col2:
        st.write("")  # æ·»åŠ ç©ºç™½ä»¥å¯¹é½æŒ‰é’®
        # æ·»åŠ æ–‡æ¡£æŒ‰é’®
        if st.button("ğŸ“¥ æ·»åŠ æ–‡æ¡£", type="primary"):
            if blog_url:
                with st.spinner("æ­£åœ¨å¤„ç†æ–‡æ¡£..."):
                    # è°ƒç”¨æ–‡æ¡£æ·»åŠ å‡½æ•°
                    if add_documents_to_qdrant(blog_url, db):
                        st.success("âœ… æ–‡æ¡£æ·»åŠ æˆåŠŸï¼ç°åœ¨å¯ä»¥å¼€å§‹æé—®äº†ã€‚")
                    else:
                        st.error("âŒ æ–‡æ¡£æ·»åŠ å¤±è´¥ï¼Œè¯·æ£€æŸ¥URLæ˜¯å¦æœ‰æ•ˆã€‚")
            else:
                st.warning("âš ï¸ è¯·å…ˆè¾“å…¥åšå®¢URL")
    
    # åˆ†éš”çº¿
    st.divider()
    
    # æ™ºèƒ½é—®ç­”éƒ¨åˆ†
    st.subheader("ğŸ’¬ æ™ºèƒ½é—®ç­”")
    
    # ç”¨æˆ·æŸ¥è¯¢è¾“å…¥
    user_query = st.text_input(
        "è¯·è¾“å…¥æ‚¨çš„é—®é¢˜:",
        placeholder="ä¾‹å¦‚ï¼šè¿™ç¯‡æ–‡ç« çš„ä¸»è¦è§‚ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ",
        help="è¾“å…¥å…³äºåšå®¢å†…å®¹çš„ä»»ä½•é—®é¢˜"
    )
    
    # é—®ç­”æ‰§è¡ŒæŒ‰é’®
    if st.button("ğŸš€ å¼€å§‹æœç´¢", type="primary"):
        if user_query:
            # æ˜¾ç¤ºå¤„ç†çŠ¶æ€
            with st.spinner("ğŸ¤– AIæ­£åœ¨æ€è€ƒä¸­..."):
                try:
                    # æ„å»ºè¾“å…¥æ•°æ®
                    inputs = {"messages": [HumanMessage(content=user_query)]}
                    
                    # æ‰§è¡ŒLangGraphå·¥ä½œæµ
                    result = generate_message(graph, inputs)
                    
                    # æ˜¾ç¤ºç»“æœ
                    if result:
                        st.subheader("ğŸ¯ æ™ºèƒ½ç­”æ¡ˆ")
                        st.write(result)
                        
                        # æ·»åŠ åé¦ˆåŒºåŸŸ
                        st.divider()
                        st.subheader("ğŸ“Š åé¦ˆ")
                        
                        # åˆ›å»ºåé¦ˆæŒ‰é’®
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            if st.button("ğŸ‘ ç­”æ¡ˆæœ‰å¸®åŠ©"):
                                st.success("æ„Ÿè°¢æ‚¨çš„åé¦ˆï¼")
                        with col2:
                            if st.button("ğŸ‘ ç­”æ¡ˆéœ€è¦æ”¹è¿›"):
                                st.info("æˆ‘ä»¬ä¼šç»§ç»­æ”¹è¿›ç³»ç»Ÿæ€§èƒ½")
                        with col3:
                            if st.button("ğŸ”„ é‡æ–°æœç´¢"):
                                st.rerun()
                    else:
                        st.error("âŒ æœªèƒ½ç”Ÿæˆç­”æ¡ˆï¼Œè¯·å°è¯•é‡æ–°è¡¨è¿°æ‚¨çš„é—®é¢˜")
                        
                except Exception as e:
                    st.error(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
                    st.info("ğŸ’¡ å»ºè®®ï¼šè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒAPIé…ç½®")
        else:
            st.warning("âš ï¸ è¯·è¾“å…¥æ‚¨çš„é—®é¢˜")
    
    # é¡µé¢åº•éƒ¨ä¿¡æ¯
    st.divider()
    st.markdown("""
    ### ğŸ” ç³»ç»Ÿå·¥ä½œåŸç†
    
    1. **æ–‡æ¡£å¤„ç†**ï¼šç³»ç»Ÿè‡ªåŠ¨æŠ“å–åšå®¢å†…å®¹å¹¶åˆ†å‰²æˆå°å—
    2. **å‘é‡åŒ–å­˜å‚¨**ï¼šä½¿ç”¨Google GeminiåµŒå…¥æ¨¡å‹å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡
    3. **æ™ºèƒ½æ£€ç´¢**ï¼šåŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦æ£€ç´¢ç›¸å…³æ–‡æ¡£ç‰‡æ®µ
    4. **ç›¸å…³æ€§è¯„ä¼°**ï¼šAIè‡ªåŠ¨è¯„ä¼°æ£€ç´¢ç»“æœçš„ç›¸å…³æ€§
    5. **æŸ¥è¯¢ä¼˜åŒ–**ï¼šå¦‚æœç»“æœä¸ç›¸å…³ï¼Œè‡ªåŠ¨é‡å†™æŸ¥è¯¢
    6. **ç­”æ¡ˆç”Ÿæˆ**ï¼šåŸºäºç›¸å…³æ–‡æ¡£ç”Ÿæˆå‡†ç¡®ã€æœ‰ç”¨çš„ç­”æ¡ˆ
    
    ### ğŸ’¡ ä½¿ç”¨æŠ€å·§
    
    - **å…·ä½“é—®é¢˜**ï¼šæå‡ºå…·ä½“ã€æ˜ç¡®çš„é—®é¢˜èƒ½è·å¾—æ›´å¥½çš„ç­”æ¡ˆ
    - **å…³é”®è¯**ï¼šåœ¨é—®é¢˜ä¸­åŒ…å«ç›¸å…³å…³é”®è¯
    - **ä¸Šä¸‹æ–‡**ï¼šæä¾›è¶³å¤Ÿçš„ä¸Šä¸‹æ–‡ä¿¡æ¯
    - **å¤šæ¬¡å°è¯•**ï¼šå¦‚æœç­”æ¡ˆä¸æ»¡æ„ï¼Œå¯ä»¥å°è¯•é‡æ–°è¡¨è¿°é—®é¢˜
    """)


# åº”ç”¨ç¨‹åºå…¥å£ç‚¹
if __name__ == "__main__":
    main()